{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.brain as fob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchsummary\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "# import resnet18 model from pytorch\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import mxnet as mx\n",
    "from mxnet import recordio\n",
    "import torch.multiprocessing as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = (224, 224)\n",
    "BS = 256\n",
    "EPOCHS = 30\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-4\n",
    "NUM_CLASSES = 10572\n",
    "NUM_WORKERS = 4\n",
    "LOG_INTERVAL = 5\n",
    "DEVICE_IDS = [[1],[1]]\n",
    "DEVICE = torch.device(\"cuda:{}\".format(DEVICE_IDS[0][0]) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CASIAWebFaceDataset(Dataset):\n",
    "    def __init__(self, path_dataset, transform=None):\n",
    "        self.transform = transform\n",
    "        # the dataset is a folder with subfolders. The subfolder name is the label,\n",
    "        # and the images are in the subfolder. Images represent their index in dataset.\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # get all subfolders in the dataset folder\n",
    "        subfolders = [f.path for f in os.scandir(path_dataset) if f.is_dir()]\n",
    "        # get all images in the subfolders\n",
    "        for label, subfolder in enumerate(subfolders):\n",
    "            for img_file in os.listdir(subfolder):\n",
    "                if img_file.endswith('.jpg') or img_file.endswith('.png'):\n",
    "                    self.imgs.append(os.path.join(subfolder, img_file))\n",
    "                    self.labels.append(label)\n",
    "        self.imgs = np.array(self.imgs)\n",
    "        self.labels = np.array(self.labels)\n",
    "        self.seq = np.arange(len(self.imgs))\n",
    "        self.id2range = defaultdict(list)\n",
    "        for i, label in enumerate(self.labels):\n",
    "            self.id2range[label].append(i)\n",
    "        self.seq_identity = np.unique(self.labels)\n",
    "        self.imgidx = np.arange(len(self.imgs))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Map global index to class ID and local index\n",
    "        actual_idx = idx\n",
    "        \n",
    "        # Read image\n",
    "        img = Image.open(self.imgs[actual_idx])\n",
    "        label = int(self.labels[actual_idx])\n",
    "        \n",
    "        # Convert to PIL and apply transforms\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "    def get_imgidx(self):\n",
    "        return self.imgidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNormalize:\n",
    "    def __call__(self, img):\n",
    "        # Convert PIL image to tensor\n",
    "        img = transforms.ToTensor()(img)\n",
    "        # Subtract 128 and divide by 128\n",
    "        img = (img * 255.0 - 128) / 128.0\n",
    "        return img\n",
    "\n",
    "class Cutout(object):\n",
    "    \"\"\"Randomly masks out one or more patches from an image.\n",
    "\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1:y2, x1:x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img\n",
    "\n",
    "train_preprocess = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(DIM, scale=(0.08, 1.0),\n",
    "                                 interpolation=transforms.InterpolationMode.LANCZOS),  # Randomly crop the image to the specified size\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.RandomRotation(30),  # Randomly rotate the image by up to 10 degrees\n",
    "    # transforms.RandomVerticalFlip(),  # Randomly flip the image vertically\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Randomly change brightness, contrast, saturation and hue\n",
    "    CustomNormalize(),\n",
    "    # Cutout(n_holes=1, length=16),  # Randomly cut out a square patch\n",
    "])\n",
    "\n",
    "test_preprocess = transforms.Compose([\n",
    "    transforms.Resize(DIM, interpolation=transforms.InterpolationMode.LANCZOS),  # Resize the image to the specified size\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    CustomNormalize()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get a sample from dataset\n",
    "# # dataset = CASIAWebFaceDataset(path_imgrec='./faces_webface_112x112/train.rec', transform=transforms.Compose([\n",
    "# #     transforms.ToTensor(),\n",
    "# # ]))\n",
    "# dataset = CASIAWebFaceDataset(path_dataset='./faces_webface_112x112_cropped', transform=transforms.Compose([\n",
    "#     transforms.Resize(DIM),\n",
    "#     transforms.ToTensor(),\n",
    "# ]))\n",
    "# print(\"Dataset size: \", len(dataset))\n",
    "# print(\"Number of classes: \", len(dataset.seq_identity))\n",
    "# print(\"Number of images: \", len(dataset.imgs))\n",
    "# print(\"Number of identities: \", len(dataset.id2range))\n",
    "# print(\"Number of images per identity: \", len(dataset.imgidx))\n",
    "\n",
    "# loader = DataLoader(dataset, batch_size=5, shuffle=True, num_workers=NUM_WORKERS)\n",
    "# img, label = next(iter(loader))\n",
    "# cropped_face = detect_and_crop_face(img[0], mtcnn, transforms.Compose([\n",
    "#     transforms.Resize(DIM),\n",
    "#     transforms.ToTensor(),\n",
    "# ]))\n",
    "# for i in range(5):\n",
    "#     plt.subplot(1, 5, i+1)\n",
    "#     plt.title(label[i].item())\n",
    "#     # get index of the image in the dataset\n",
    "#     idx = dataset.imgidx[i]\n",
    "#     print(\"Image index: \", idx)\n",
    "#     plt.imshow(img[i].permute(1, 2, 0).numpy())\n",
    "#     plt.axis('off')\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# print(\"Cleared CUDA cache\")\n",
    "# assert False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMSoftmax(nn.Module):\n",
    "    '''\n",
    "    The am softmax as seen on https://arxiv.org/pdf/1801.05599.pdf,\n",
    "\n",
    "        in_features: size of the embedding, eg. 512\n",
    "        n_classes: number of classes on the classification task\n",
    "        s: s parameter of loss, standard = 30.\n",
    "        m: m parameter of loss, standard = 0.4, best between 0.35 and 0.4 according to paper.\n",
    "\n",
    "        *inputs: tensor shaped (batch_size X embedding_size)\n",
    "        output : tensor shaped (batch_size X n_classes) AM_softmax logits for NLL_loss.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, in_features, n_classes, s=30, m=0.4):\n",
    "        super(AMSoftmax, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, n_classes, bias=False)\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, *inputs):\n",
    "        # x_vector = F.normalize(inputs[0], p=2, dim=-1)\n",
    "        # self.linear.weight.data = F.normalize(self.linear.weight.data, p=2, dim=-1, eps=1e-10)\n",
    "        # logits = self.linear(x_vector)\n",
    "        x_vector = inputs[0]\n",
    "        normed_weight = F.normalize(self.linear.weight, p=2, dim=-1, eps=1e-10)\n",
    "        logits = F.linear(x_vector, normed_weight)\n",
    "        scaled_logits = (logits - self.m)*self.s\n",
    "        return  scaled_logits - self._am_logsumexp(logits)\n",
    "\n",
    "    def _am_logsumexp(self, logits):\n",
    "        '''\n",
    "        logsumexp designed for am_softmax, the computation is numerically stable\n",
    "\n",
    "        '''\n",
    "        max_x = torch.max(logits, dim=-1)[0].unsqueeze(-1)\n",
    "        term1 = (self.s*(logits - (max_x + self.m))).exp()\n",
    "        term2 = (self.s * (logits - max_x)).exp().sum(-1).unsqueeze(-1) \\\n",
    "                - (self.s * (logits - max_x)).exp()\n",
    "        return self.s*max_x + (term2 + term1).log()\n",
    "    \n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # self.relu = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# How can I modify the model to output embeddings of size 128?\n",
    "# 1. Create a new model that outputs embeddings\n",
    "# 2. Modify the last layer of the model to output embeddings\n",
    "# 3. Use a hook to extract embeddings from the model\n",
    "# 4. Use a custom loss function to train the model\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10572, dropout=0.4):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        out = F.normalize(out, p=2, dim=-1, eps=1e-10)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(model, classifier, data_loader, device, message):\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            embeddings = model(images)  # Extract features\n",
    "            logits = classifier(embeddings)  # Compute AMSoftmax logits\n",
    "            predictions = torch.argmax(logits, dim=1)  # Get class with max probability\n",
    "            \n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"✅ Classification Accuracy for {message}: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_AMSoftmax(model: nn.Module, classifier: nn.Module, data_loader: DataLoader, val_loader: DataLoader,\n",
    "                    optimizer: optim.Optimizer, scheduler: optim.lr_scheduler, \n",
    "                    criterion: nn.Module, epochs: int, device: torch.device, \n",
    "                    retain_graph: bool, checkpoint_interval: int = 10):\n",
    "\n",
    "    train_losses = []\n",
    "    tmstmp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    best_loss = np.inf\n",
    "    vacc = 0\n",
    "\n",
    "    # tmstmp = \"20250313-074759\"\n",
    "\n",
    "    log_dir = f\"runs/{DIM[0]}x{DIM[1]}_ResNet18_AMSoftmax_{tmstmp}\"\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    print(f\"Started Training at {tmstmp}\")\n",
    "    \n",
    "    for e, epoch in enumerate(tqdm(range(epochs), desc=\"Epochs\")):\n",
    "        model.train()\n",
    "        classifier.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(tqdm(data_loader, desc=\"Batches\")):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            embeddings = model(images)  # Extract embeddings from model\n",
    "            logits = classifier(embeddings)  # Compute AMSoftmax logits\n",
    "            loss = criterion(logits, labels)  # Compute NLL loss\n",
    "\n",
    "            loss.backward(retain_graph=retain_graph)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # print(f\"Batch {i+1}/{len(data_loader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "        avg_loss = running_loss / len(data_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        classifier.eval()\n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Validation\")):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                embeddings = model(images)\n",
    "                logits = classifier(embeddings)\n",
    "                loss = criterion(logits, labels)\n",
    "                running_loss += loss.item()\n",
    "            # print(f\"Batch {i+1}/{len(val_loader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "        # Log per epoch\n",
    "        writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "        writer.add_scalar('Loss/val', running_loss / len(val_loader), epoch)\n",
    "\n",
    "        # Checkpoint saving\n",
    "        if (epoch + 1) % checkpoint_interval == 0:\n",
    "            checkpoint_path = os.path.join(log_dir, f'checkpoint_epoch_{epoch + 1}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'classifier_state_dict': classifier.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "            train_acc = test_classifier(model, classifier, data_loader, device, \"Training\")\n",
    "            val_acc = test_classifier(model, classifier, val_loader, device, \"Validation\")\n",
    "            writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "            writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "            if val_acc > vacc:\n",
    "                vacc = val_acc\n",
    "                torch.save(model.state_dict(), f\"{log_dir}/{DIM[0]}x{DIM[1]}_ResNet18_AMSoftmax_validation_{tmstmp}.pt\")\n",
    "                print(f\"Saved best model with validation accuracy {vacc}\")\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "        # Save Best Model\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), f\"{log_dir}/{DIM[0]}x{DIM[1]}_ResNet18_AMSoftmax_{tmstmp}.pt\")\n",
    "            print(f\"Saved best model with loss: {best_loss:.4f}\")\n",
    "\n",
    "    print(f\"Finished Training at {time.strftime('%Y%m%d-%H%M%S')} with best validation accuracy {vacc:.4f}\")\n",
    "    writer.close()\n",
    "\n",
    "    return model, train_losses, tmstmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_casia_webface(embedding_model, classifier, optimizer, device, device_ids):\n",
    "    # Set up paths\n",
    "    # rec_path = \"/home/ichitu/py-files/faces_webface_112x112/train.rec\"\n",
    "    # path_dataset = \"/home/ichitu/py-files/faces_webface_224x224_cropped_mtcnn\"\n",
    "    path_dataset = \"/home/ichitu/py-files/faces_webface_112x112_cropped\"\n",
    "\n",
    "    \n",
    "    # Load datasets\n",
    "    print(\"Loading CASIA WebFace dataset...\")\n",
    "    # casia_dataset = CASIAWebFaceDataset(\n",
    "    #     path_imgrec=rec_path,\n",
    "    #     transform=train_preprocess\n",
    "    # )\n",
    "\n",
    "    casia_dataset = CASIAWebFaceDataset(\n",
    "        path_dataset=path_dataset,\n",
    "        transform=train_preprocess\n",
    "    )\n",
    "\n",
    "    train_idx, test_idx = train_test_split(range(len(casia_dataset)), test_size=0.2, random_state=42)\n",
    "    train_dataset = torch.utils.data.Subset(casia_dataset, train_idx)\n",
    "    test_dataset = torch.utils.data.Subset(casia_dataset, test_idx)\n",
    "    # val_idx, test_idx = train_test_split(test_idx, test_size=0.7, random_state=42)\n",
    "    # val_dataset = torch.utils.data.Subset(casia_dataset, val_idx)\n",
    "    # test_dataset = torch.utils.data.Subset(casia_dataset, test_idx)\n",
    "\n",
    "    print(len(train_dataset))\n",
    "    # print(len(val_dataset))\n",
    "    print(len(test_dataset))\n",
    "\n",
    "    \n",
    "\n",
    "    print(len(casia_dataset))\n",
    "    \n",
    "    # print(\"Loading LFW dataset...\")\n",
    "    # lfw_dataset = foz.load_zoo_dataset(\"lfw\")\n",
    "    \n",
    "    # Find and filter overlapping identities\n",
    "    # print(\"Finding overlapping identities...\")\n",
    "    # overlapping_ids = find_overlapping_identities(casia_dataset, lfw_dataset)\n",
    "    \n",
    "    # print(\"Creating filtered dataset...\")\n",
    "    # filtered_dataset = FilteredCASIADataset(casia_dataset, overlapping_ids)\n",
    "    # filtered_dataset = casia_dataset\n",
    "    \n",
    "    # Create data loader\n",
    "    # train_loader = DataLoader(\n",
    "    #     train_dataset, \n",
    "    #     batch_size=BS * len(device_ids),\n",
    "    #     shuffle=True, \n",
    "    #     num_workers=2,\n",
    "    #     pin_memory=True\n",
    "    # )\n",
    "\n",
    "    # val_loader = DataLoader(\n",
    "    #     val_dataset, \n",
    "    #     batch_size=BS * len(device_ids),\n",
    "    #     shuffle=True, \n",
    "    #     num_workers=2,\n",
    "    #     pin_memory=True\n",
    "    # )\n",
    "\n",
    "    # test_loader = DataLoader(\n",
    "    #     test_dataset, \n",
    "    #     batch_size=BS * len(device_ids),\n",
    "    #     shuffle=True, \n",
    "    #     num_workers=2,\n",
    "    #     pin_memory=True\n",
    "    # )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        casia_dataset,\n",
    "        batch_size=BS,\n",
    "        num_workers=4,\n",
    "        sampler=torch.utils.data.SubsetRandomSampler(train_idx),\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # val_loader = DataLoader(\n",
    "    #     CASIAWebFaceDataset(\n",
    "    #         path_imgrec=rec_path,\n",
    "    #         transform=test_preprocess\n",
    "    #     ),\n",
    "    #     batch_size=BS,\n",
    "    #     num_workers=2,\n",
    "    #     sampler=torch.utils.data.SubsetRandomSampler(val_idx),\n",
    "    #     pin_memory=True\n",
    "    # )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        CASIAWebFaceDataset(\n",
    "            path_dataset=path_dataset,\n",
    "            transform=test_preprocess\n",
    "        ),\n",
    "        batch_size=BS,\n",
    "        num_workers=2,\n",
    "        sampler=torch.utils.data.SubsetRandomSampler(test_idx),\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Set up model\n",
    "    print(\"Setting up model...\")\n",
    "    \n",
    "    # Set up optimizer (include both models' parameters)\n",
    "    optimizer = optim.SGD(\n",
    "        list(embedding_model.parameters()) + list(classifier.parameters()),\n",
    "        lr=LR,\n",
    "        momentum=MOMENTUM,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    # optimizer = optim.Adam(\n",
    "    #     embedding_model.parameters(),\n",
    "    #     lr=0.001,\n",
    "    #     weight_decay=5e-4,\n",
    "    #     eps=1e-8\n",
    "    # )\n",
    "    # optimizer = optim.SGD(\n",
    "    #     list(embedding_model.parameters()) + list(classifier.parameters()),\n",
    "    #     lr=optimizer['param_groups'][0]['lr'],\n",
    "    #     momentum=MOMENTUM,\n",
    "    #     weight_decay=WEIGHT_DECAY\n",
    "    # )\n",
    "\n",
    "    # Set up scheduler\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    # scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n",
    "    # scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=10, eta_min=1e-5)\n",
    "    # scheduler = optim.lr_scheduler.MultiStepLR( optimizer, \n",
    "    #                                             milestones=[int(EPOCHS*0.5), int(EPOCHS*0.8), int(EPOCHS*0.9)],\n",
    "    #                                             gamma=0.1)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                milestones=[16, 24, 28],\n",
    "                                                gamma=0.1)\n",
    "    # Set up loss\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Train\n",
    "    print(\"Starting training...\")\n",
    "    model, losses, timestamp = train_AMSoftmax(\n",
    "        model=embedding_model,\n",
    "        classifier=classifier,\n",
    "        data_loader=train_loader,\n",
    "        # val_loader=val_loader,\n",
    "        val_loader=test_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        criterion=criterion,\n",
    "        epochs=EPOCHS,  # Adjust as needed\n",
    "        device=device,\n",
    "        retain_graph=False,\n",
    "        checkpoint_interval=LOG_INTERVAL\n",
    "    )\n",
    "\n",
    "    print(\"Testing model...\")\n",
    "    test_acc = test_classifier(embedding_model, classifier, test_loader, device, \"Test\")\n",
    "    \n",
    "    return model, losses, timestamp, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_casia_webface_normal_split(embedding_model, classifier, optimizer, device, device_ids):\n",
    "    # Set up paths\n",
    "    # rec_path = \"/home/ichitu/py-files/faces_webface_112x112/train.rec\"\n",
    "    path_dataset = \"/home/ichitu/py-files/faces_webface_112x112_cropped\"\n",
    "    \n",
    "    # Load datasets\n",
    "    print(\"Loading CASIA WebFace dataset...\")\n",
    "    # casia_dataset = CASIAWebFaceDataset(\n",
    "    #     path_imgrec=rec_path,\n",
    "    #     transform=test_preprocess\n",
    "    # )\n",
    "    casia_dataset = CASIAWebFaceDataset(\n",
    "        path_dataset=path_dataset,\n",
    "        transform=train_preprocess\n",
    "    )\n",
    "\n",
    "    train_length = int(len(casia_dataset) * 0.8)\n",
    "    test_length = len(casia_dataset) - train_length\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(casia_dataset, [train_length, test_length])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BS,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BS,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "   \n",
    "    # Set up model\n",
    "    print(\"Setting up model...\")\n",
    "    \n",
    "    # Set up optimizer (include both models' parameters)\n",
    "    optimizer = optim.SGD(\n",
    "        list(embedding_model.parameters()) + list(classifier.parameters()),\n",
    "        lr=LR,\n",
    "        momentum=MOMENTUM,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    # optimizer = optim.Adam(\n",
    "    #     embedding_model.parameters(),\n",
    "    #     lr=0.001,\n",
    "    #     weight_decay=5e-4,\n",
    "    #     eps=1e-8\n",
    "    # )\n",
    "    # optimizer = optim.SGD(\n",
    "    #     list(embedding_model.parameters()) + list(classifier.parameters()),\n",
    "    #     lr=optimizer['param_groups'][0]['lr'],\n",
    "    #     momentum=MOMENTUM,\n",
    "    # weight_decay=WEIGHT_DECAY\n",
    "    # )\n",
    "\n",
    "    # Set up scheduler\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    # scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n",
    "    # scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=10, eta_min=1e-5)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR( optimizer, \n",
    "                                                milestones=[int(EPOCHS*0.5), int(EPOCHS*0.8), int(EPOCHS*0.9)],\n",
    "                                                gamma=0.1)\n",
    "    # Set up loss\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Train\n",
    "    print(\"Starting training...\")\n",
    "    model, losses, timestamp = train_AMSoftmax(\n",
    "        model=embedding_model,\n",
    "        classifier=classifier,\n",
    "        data_loader=train_loader,\n",
    "        # val_loader=val_loader,\n",
    "        val_loader=test_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        criterion=criterion,\n",
    "        epochs=EPOCHS,  # Adjust as needed\n",
    "        device=device,\n",
    "        retain_graph=False,\n",
    "        checkpoint_interval=LOG_INTERVAL\n",
    "    )\n",
    "\n",
    "    print(\"Testing model...\")\n",
    "    test_acc = test_classifier(embedding_model, classifier, test_loader, device, \"Test\")\n",
    "    \n",
    "    return model, losses, timestamp, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, classifier, check_point_dir, device='cuda'):\n",
    "    check_point = torch.load(check_point_dir, map_location=device)\n",
    "    state_dict = check_point['model_state_dict']\n",
    "    # Create new OrderedDict without 'module.' prefix\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('module.'):\n",
    "            name = k[7:] # remove 'module.' prefix\n",
    "        else:\n",
    "            name = k\n",
    "        new_state_dict[name] = v\n",
    "    \n",
    "    # Load the weights\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    # Set to evaluation mode\n",
    "    # model.eval()\n",
    "    # print(f\"Model loaded from {path}\")\n",
    "    state_dict = check_point['classifier_state_dict']\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('module.'):\n",
    "            name = k[7:] # remove 'module.' prefix\n",
    "        else:\n",
    "            name = k\n",
    "        new_state_dict[name] = v\n",
    "    # Load the weights\n",
    "    classifier.load_state_dict(new_state_dict)\n",
    "\n",
    "    optimizer = torch.load(check_point_dir, map_location=device)['optimizer_state_dict']\n",
    "\n",
    "    return model, classifier, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert 1==2\n",
    "\n",
    "check_point_dir = \"./runs/112x96_ResNet18_AMSoftmax_20250403-164108/checkpoint_epoch_30.pth\"\n",
    "\n",
    "device_ids = DEVICE_IDS\n",
    "device = DEVICE\n",
    "classifier = AMSoftmax(512, 10572)\n",
    "# embedding_model = EmbeddingResNet18(512)\n",
    "embedding_model = ResNet18(512)\n",
    "# embedding_model = Resface20(512)\n",
    "# embedding_model, classifier, optimizer = load_model(embedding_model, classifier, check_point_dir, device)\n",
    "# embedding_model = load_model(embedding_model, '/home/ichitu/py-files/runs/112x96_ResNet18_AMSoftmax_20250322-161021/112x96_ResNet18_AMSoftmax_20250322-161021.pt', 'cuda:3')\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Avaible {torch.cuda.device_count()} GPUs and using {device_ids}\")\n",
    "    embedding_model = nn.DataParallel(embedding_model, device_ids=device_ids[0])\n",
    "    classifier = nn.DataParallel(classifier, device_ids=device_ids[1])\n",
    "\n",
    "# embedding_model = embedding_model.to(device)\n",
    "# classifier = classifier.to(device)\n",
    "# embedding_model.load_state_dict(torch.load(\"Models-pt/112x96_ResNet18_AMSoftmax_20250313-074759.pt\"))\n",
    "# print(embedding_model)\n",
    "# print(classifier)\n",
    "# print(optimizer)\n",
    "# # assert False\n",
    "\n",
    "optimizer = torch.load(check_point_dir, map_location=device)['optimizer_state_dict']\n",
    "\n",
    "embedding_model, train_losses, tmstmp, test_acc = train_on_casia_webface(embedding_model, classifier, optimizer, device, device_ids)\n",
    "\n",
    "# embedding_model, train_losses, tmstmp, test_acc = train_on_casia_webface_normal_split(embedding_model, classifier, optimizer, device, device_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
